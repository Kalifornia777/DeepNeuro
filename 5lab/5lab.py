import torch
import torch.nn as nn
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader
import os
import shutil

# --- 1. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π ---
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"–†–∞–±–æ—Ç–∞–µ–º –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ: {device}")

# --- 2. –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö ---
def reorganize_dataset(directory):
    """–ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏"""
    if not os.path.exists(directory):
        print(f"–ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {directory}")
        return

    label = os.path.basename(directory)
    for idx, file in enumerate(os.listdir(directory)):
        path = os.path.join(directory, file)
        if os.path.isfile(path):
            ext = os.path.splitext(file)[1].lower()
            if ext in ['.jpg', '.jpeg', '.png']:
                new_filename = f"{label}_{idx}{ext}"
                new_path = os.path.join(directory, new_filename)
                shutil.move(path, new_path)
                print(f"‚úîÔ∏è {file} --> {new_filename}")

# –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º –∫–ª–∞—Å—Å–∞–º –∏ –ø–æ–¥–Ω–∞–±–æ—Ä—É (train/test)
classes = ['city', 'money', 'rappers']
splits = ['train', 'test']

for split in splits:
    for cls in classes:
        reorganize_dataset(os.path.join('custom_dataset', split, cls))

# --- 3. –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ---
transform_pipeline = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406], 
        std=[0.229, 0.224, 0.225]
    )
])

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
data_root = os.path.abspath('custom_dataset')

train_data = datasets.ImageFolder(root=os.path.join(data_root, 'train'), transform=transform_pipeline)
test_data = datasets.ImageFolder(root=os.path.join(data_root, 'test'), transform=transform_pipeline)

train_loader = DataLoader(train_data, batch_size=32, shuffle=True)
test_loader = DataLoader(test_data, batch_size=32, shuffle=False)

print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—É—á–∞—é—â–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(train_data)}")
print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(test_data)}")

# --- 4. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ ---
# –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é —Å–µ—Ç—å DenseNet121
model = models.densenet121(pretrained=True)

# –ó–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ–º –≤—Å–µ —Å–ª–æ–∏ –∫—Ä–æ–º–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
for param in model.features.parameters():
    param.requires_grad = False

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π –ø–æ–¥ 3 –∫–ª–∞—Å—Å–∞
model.classifier = nn.Linear(model.classifier.in_features, 3)
model = model.to(device)

# --- 5. –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è ---
loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)

# --- 6. –ü—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è ---
print("\nüöÄ –û–±—É—á–µ–Ω–∏–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è!")

num_epochs = 5
for epoch in range(num_epochs):
    model.train()
    epoch_loss = 0

    for inputs, targets in train_loader:
        inputs, targets = inputs.to(device), targets.to(device)

        optimizer.zero_grad()
        outputs = model(inputs)
        loss = loss_fn(outputs, targets)
        loss.backward()
        optimizer.step()

        epoch_loss += loss.item()

    avg_loss = epoch_loss / len(train_loader)
    print(f"–≠–ø–æ—Ö–∞ [{epoch+1}/{num_epochs}], –°—Ä–µ–¥–Ω—è—è –ø–æ—Ç–µ—Ä—è: {avg_loss:.4f}")

# --- 7. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ ---
print("\nüß™ –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ...")

model.eval()
correct_predictions = 0
total_predictions = 0

with torch.no_grad():
    for inputs, targets in test_loader:
        inputs, targets = inputs.to(device), targets.to(device)
        outputs = model(inputs)
        _, predicted = torch.max(outputs, 1)
        total_predictions += targets.size(0)
        correct_predictions += (predicted == targets).sum().item()

accuracy = (correct_predictions / total_predictions) * 100
print(f"–¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {accuracy:.2f}%")

# --- 8. –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å ---
model_save_path = "densenet121_city_money_rappers.pth"
torch.save(model.state_dict(), model_save_path)
print(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∫–∞–∫ '{model_save_path}'")
